fn equal(lhs: char const[], rhs: char const[]) -> bool
{
    if @len(lhs) != @len(rhs) { return false; }
    var idx := 0u;
    while idx < @len(lhs) {
        if lhs[idx] != rhs[idx] { return false; }
        idx = idx + 1u;
    }
    return true;
}

fn find(string: char const[], substr: char const[], start: u64) -> u64
{
    var idx := start;
    while idx + @len(substr) <= @len(string) {
        let curr_substr := string[idx : idx + @len(substr)];
        if equal(substr, curr_substr) {
            return idx;
        }
        idx = idx + 1u;
    }
    return @len(string);
}

struct tokenizer
{
    _string: char const[];
    _delim: char const[];
    _start: u64;
    _curr: u64;
    _started: bool;
    _finished: bool;

    fn advance(self: &) -> null
    {
        if self._started {
            self._start = self._curr + @len(self._delim);
            if self._start > @len(self._string) {
                self._finished = true;
                self._start = @len(self._string);
                self._curr = @len(self._string);
            }
            else {
                self._curr = find(self._string, self._delim, self._start);
            }
        }
        else { # first time
            self._curr = find(self._string, self._delim, self._start);
            self._started = true;
        }
    }

    fn valid(self: const&) -> bool
    {
        return !self._finished;
    }

    fn current(self: const&) -> char const[]
    {
        return self._string[self._start : self._curr];
    }

    fn create(input: char const[], delim: char const[]) -> tokenizer
    {
        var t := tokenizer(input, delim, 0u, 0u, false, false);
        t.advance(); # prime the tokenizer at the first word
        return t;
    }
}

fn contains(string: char const[], substr: char const[]) -> bool
{
    return find(string, substr, 0u) != @len(string);
}

fn occurrences(string: char const[], substr: char const[]) -> u64
{
    var count := 0u;
    var idx := 0u;
    while idx < @len(string) {
        let curr_substr := string[idx : idx + @len(substr)];
        if equal(substr, curr_substr) {
            count = count + 1u;
            idx = idx + @len(substr);
        } else {
            idx = idx + 1u;
        }
    }
    return count;
}

fn replace(a: arena&, string: char const[], from: char const[], to: char const[]) -> char const[]
{
    let new_size := @len(from) == @len(to) ? @len(string)
                                           : @len(string) + occurrences(string, from) * (@len(to) - @len(from));

    var new_string := new(a, new_size) ' ';
    var idx := 0u;
    var tok := tokenizer.create(string, from);
    assert tok.valid(); # There is always at least one token (it may be the whole string)
    let curr := tok.current();
    let size := @len(curr);
    @copy(new_string[idx : idx + size], tok.current());
    idx = idx + size;
    tok.advance();

    while tok.valid() {
        @copy(new_string[idx : idx + @len(to)], to);
        idx = idx + @len(to);

        let curr := tok.current();
        let size := @len(curr);
        @copy(new_string[idx : idx + size], tok.current());
        idx = idx + size;
        tok.advance();
    }

    return new_string;
}

fn to_i64(c: char) -> i64
{
    let x := c as i64;
    if 47 < x && x < 58 {
        return x - 48;
    }
    return -1;
}